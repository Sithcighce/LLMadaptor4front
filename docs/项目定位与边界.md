# é¡¹ç›®å®šä½ä¸è¾¹ç•Œè§„åˆ’

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**åˆ›å»ºæ—¥æœŸ**ï¼š2025-10-20  
**è§’è‰²**ï¼šåŒé‡è§„åˆ’è€…è§†è§’

---

## âš ï¸ æ ¸å¿ƒæ¶æ„ - å¿…è¯»

### ğŸ¯ ç»Ÿä¸€çš„ä¸‰ç§æ¨ç†æ¨¡å¼

**è¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ LLM è¿æ¥å™¨åº“,æ”¯æŒä¸‰ç§åŒç­‰é‡è¦çš„æ¨ç†æ¨¡å¼:**

#### 1ï¸âƒ£ å‰ç«¯ BYOK (Bring Your Own Key)
- ç”¨æˆ·åœ¨å‰ç«¯ UI ç²˜è´´è‡ªå·±çš„ API Key
- Key å­˜å‚¨åœ¨æµè§ˆå™¨ localStorage
- å‰ç«¯ç›´æ¥è°ƒç”¨ OpenAI/Anthropic/Gemini ç­‰äº‘ç«¯ API
- **é€‚ç”¨äº**: ä¸ªäººé¡¹ç›®ã€å°å‹åº”ç”¨ã€ç”¨æˆ·è‡ªå·±ç®¡ç†å¯†é’¥

å¼•ç”¨ `é¡¹ç›®ç›®æ ‡.md`:
> ä¸æƒ³è‡ªå·±å……å€¼ - è®©ç”¨æˆ·ç”¨è‡ªå·±çš„API Keyä¸é¦™å—?  
> ä¸æƒ³ç®¡ç†ç”¨æˆ·å¯†é’¥ - è´£ä»»å¤ªå¤§,æ•°æ®å®‰å…¨é—®é¢˜ä¸€å †

#### 2ï¸âƒ£ ç«¯ä¾§æ¨ç† (On-Device Inference)
- Chrome AI - æµè§ˆå™¨å†…ç½® AI èƒ½åŠ›
- WebLLM - æµè§ˆå™¨ç«¯ WASM æ¨ç†
- æ— éœ€ API Key,æ— éœ€ç½‘ç»œ,å®Œå…¨æœ¬åœ°è¿è¡Œ
- **é€‚ç”¨äº**: éšç§æ•æ„Ÿåœºæ™¯ã€ç¦»çº¿ä½¿ç”¨ã€å…è´¹ä½“éªŒ

#### 3ï¸âƒ£ åç«¯ä»£ç† (Backend Proxy / Local Server)
- Backend Proxy - ä¼ä¸šç»Ÿä¸€ç®¡ç† API Key
- LM Studio - æœ¬åœ°æ¨¡å‹æœåŠ¡å™¨
- åç«¯æ·»åŠ å¯†é’¥,å‰ç«¯æ— éœ€å¤„ç†
- **é€‚ç”¨äº**: ä¼ä¸šå†…éƒ¨å·¥å…·ã€æœ¬åœ°æ¨¡å‹ã€ç»Ÿä¸€ç®¡ç†

**ä¸‰ç§æ¨¡å¼åŒç­‰é‡è¦,ç”¨æˆ·æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„æ¨¡å¼ã€‚**

---

## ğŸ­ åŒé‡è§†è§’

### è§†è§’ 1ï¼šGoogle Audio é¡¹ç›®è´Ÿè´£äºº
- **ç›®æ ‡**ï¼šå®ç° STT + AI èŠå¤©åŠŸèƒ½
- **éœ€æ±‚**ï¼šéœ€è¦ä¸€ä¸ªå¥½ç”¨çš„ LLM é€‚é…å±‚
- **æœŸæœ›**ï¼šllm-connector æä¾›ç¨³å®šã€æ˜“ç”¨çš„ API

### è§†è§’ 2ï¼šllm-connector åº“è´Ÿè´£äºº
- **ç›®æ ‡**ï¼šæ‰“é€ é€šç”¨çš„å‰ç«¯ LLM é€‚é…åº“
- **å®šä½**ï¼šç±»ä¼¼ `react-query` ä¹‹äºæ•°æ®è¯·æ±‚
- **è¾¹ç•Œ**ï¼šä¸“æ³¨é€‚é…å±‚ï¼Œä¸æ¶‰åŠä¸šåŠ¡é€»è¾‘

---

## ğŸ¯ llm-connector çš„å®šä½

### ä¸€å¥è¯å®šä½
> **A BYOK React library for unified LLM provider management.**
> 
> ä¸€ä¸ªåŸºäº BYOK æ¶æ„çš„ React åº“ï¼Œç”¨äºç»Ÿä¸€ç®¡ç†å¤š LLM æä¾›å•†ã€‚ç”¨æˆ·ç²˜è´´è‡ªå·±çš„ API Keyï¼Œå‰ç«¯ç›´æ¥è°ƒç”¨ã€‚

### ç±»æ¯”å‚è€ƒ
- **ç±»ä¼¼ `react-query`** - ç»Ÿä¸€æ•°æ®è¯·æ±‚ï¼Œä½†ä¸å…³å¿ƒå…·ä½“ä¸šåŠ¡
- **ç±»ä¼¼ `react-hook-form`** - æä¾›è¡¨å•ç®¡ç†ï¼Œä½†ä¸é™å®šè¡¨å•æ ·å¼
- **ç±»ä¼¼ `next-auth`** - æä¾›è®¤è¯æŠ½è±¡ï¼Œä½†ä¸é™å®š UI

---

## âœ… llm-connector åº”è¯¥åšä»€ä¹ˆ

### 1. æ ¸å¿ƒåŠŸèƒ½ï¼šProvider æŠ½è±¡

```typescript
// ç»Ÿä¸€æ¥å£ï¼Œå±è”½å·®å¼‚
const result = await llmClient.chat({
  messages: [{ role: 'user', content: 'Hello' }],
  stream: true,
});

// æ”¯æŒçš„ Providers
- OpenAI / Anthropic / Gemini  (äº‘ç«¯API)
- WebLLM                        (æµè§ˆå™¨WASM)
- Chrome AI                     (æµè§ˆå™¨å†…ç½®)
- LM Studio                     (æœ¬åœ°æœåŠ¡å™¨)
- Backend Proxy                 (è‡ªå®šä¹‰åç«¯)
```

### 2. çŠ¶æ€ç®¡ç†ï¼šReact Context + Hooks

```typescript
// Provider ç»„ä»¶
<LlmConnectorProvider name="chat" storageKey="chat-config">
  <App />
</LlmConnectorProvider>

// Hook ä½¿ç”¨
const { llmClient, states, handlers } = useLlmConnector('chat');

// å¤šå®ä¾‹æ”¯æŒ
<LlmConnectorProvider name="chat">...</LlmConnectorProvider>
<LlmConnectorProvider name="summarizer">...</LlmConnectorProvider>
```

### 3. é…ç½®æŒä¹…åŒ–

```typescript
// è‡ªåŠ¨ä¿å­˜åˆ° localStorage
{
  "providerId": "openai",
  "apiKey": "sk-...",
  "model": "gpt-4o",
  "callMode": "backend",
  "backendUrl": "/api/ai/proxy"
}
```

### 4. å…³é”® UI ç»„ä»¶ï¼ˆâœ… æ¨èé›†æˆï¼‰

#### 4.1 é…ç½®é¢æ¿ - `<LlmConnectorSettings />`
**åŠŸèƒ½**ï¼š
- Provider é€‰æ‹©ä¸‹æ‹‰æ¡†
- API Key è¾“å…¥ï¼ˆå¯é€‰ï¼‰
- Base URL è¾“å…¥ï¼ˆå¯é€‰ï¼‰
- æ¨¡å‹é€‰æ‹©
- å‰ç«¯/åç«¯æ¨¡å¼åˆ‡æ¢
- è¿æ¥/æ–­å¼€æŒ‰é’®

**ç†ç”±**ï¼š
- âœ… è¿™æ˜¯**é…ç½®**è€Œé**ä¸šåŠ¡ç•Œé¢**
- âœ… æ¯ä¸ªä½¿ç”¨è€…éƒ½éœ€è¦
- âœ… å¯ä»¥è‡ªå®šä¹‰æ ·å¼ï¼ˆé€šè¿‡ CSS æˆ– Tailwindï¼‰
- âœ… å¯é€‰ä½¿ç”¨ï¼ˆçº¯ä»£ç é…ç½®ä¹Ÿå¯ä»¥ï¼‰

```typescript
// ä½¿ç”¨åº“æä¾›çš„é…ç½®é¢æ¿
<LlmConnectorSettings 
  connectorName="my-chat"
  showAdvanced={true}
  className="custom-styles"
/>

// æˆ–è€…å®Œå…¨è‡ªå®šä¹‰
const { states, handlers } = useLlmConnector('my-chat');
<MyCustomSettingsUI 
  providerId={states.providerId}
  onProviderChange={handlers.setProviderId}
  // ...
/>
```

#### 4.2 è¿æ¥çŠ¶æ€æŒ‡ç¤ºå™¨ - `<ConnectionStatus />`
```typescript
<ConnectionStatus connectorName="my-chat" />
// æ˜¾ç¤ºï¼šğŸŸ¢ å·²è¿æ¥ | ğŸŸ¡ è¿æ¥ä¸­ | ğŸ”´ æœªè¿æ¥
```

#### 4.3 Token ä½¿ç”¨ç»Ÿè®¡ - `<TokenUsageDisplay />`
```typescript
<TokenUsageDisplay 
  connectorName="my-chat"
  showCost={true}  // å¯é€‰æ˜¾ç¤ºè´¹ç”¨ä¼°ç®—
/>
// æ˜¾ç¤ºï¼šè¾“å…¥ 500 tokens | è¾“å‡º 300 tokens | çº¦ $0.02
```

### 5. å‰åç«¯æ¨¡å¼åˆ‡æ¢

```typescript
// å‰ç«¯ç›´è°ƒï¼ˆç”¨æˆ·æä¾› API Keyï¼‰
handlers.setCallMode('frontend');
handlers.setProviderId('openai');
handlers.setApiKey('user-key');

// åç«¯ä»£ç†ï¼ˆåç«¯ç»Ÿä¸€ç®¡ç† API Keyï¼‰
handlers.setCallMode('backend');
handlers.setBackendUrl('/api/ai/proxy');
```

### 6. ç±»å‹å®‰å…¨å’Œæ–‡æ¡£

```typescript
// å®Œæ•´çš„ TypeScript ç±»å‹
export interface ChatRequest {
  messages: ChatMessage[];
  model?: string;
  temperature?: number;
  max_tokens?: number;
  stream?: boolean;
}

// è¯¦ç»†çš„ JSDoc æ³¨é‡Š
/**
 * Send a chat message to the LLM
 * @param request - Chat request configuration
 * @returns ChatResult with text, usage, and metadata
 * @throws Error if client is not connected
 */
async chat(request: ChatRequest): Promise<ChatResult>
```

---

## âŒ llm-connector ä¸åº”è¯¥åšä»€ä¹ˆ

### 1. âŒ å®Œæ•´çš„èŠå¤©ç•Œé¢

```typescript
// âŒ ä¸æä¾›è¿™ä¸ª
<ChatInterface>
  <MessageList messages={messages} />
  <InputBox onSend={handleSend} />
  <SidePanel />
</ChatInterface>
```

**ç†ç”±**ï¼š
- æ¯ä¸ªé¡¹ç›®çš„èŠå¤©ç•Œé¢å·®å¼‚å¤ªå¤§
- Google Audio æœ‰ STT é›†æˆã€PDF Reader æœ‰åˆ†æ®µå±•ç¤º
- è¿™æ˜¯**ä¸šåŠ¡ UI**ï¼Œä¸æ˜¯é…ç½® UI

### 2. âŒ å¯¹è¯å†å²ç®¡ç†

```typescript
// âŒ ä¸åšè¿™ä¸ª
const { messages, addMessage, clearHistory } = useChatHistory();
```

**ç†ç”±**ï¼š
- æœ‰äººç”¨ Reduxï¼Œæœ‰äººç”¨ Zustandï¼Œæœ‰äººç”¨ Context
- æœ‰äººå­˜ localStorageï¼Œæœ‰äººå­˜ IndexedDBï¼Œæœ‰äººå­˜åç«¯

### 3. âŒ åç«¯å®ç°ä»£ç 

```typescript
// âŒ ä¸åŒ…å«è¿™ä¸ª
// app/api/ai/proxy/route.ts
export async function POST(request: NextRequest) {
  // ...åç«¯ä»£ç†é€»è¾‘
}
```

**ç†ç”±**ï¼š
- åç«¯æŠ€æœ¯æ ˆå¤šæ ·ï¼ˆNext.js / Express / Fastifyï¼‰
- ä½†å¯ä»¥æä¾›**åç«¯å®ç°æŒ‡å—**å’Œ**ç¤ºä¾‹ä»£ç **

### 4. âŒ ä¸šåŠ¡ç›¸å…³åŠŸèƒ½

```typescript
// âŒ ä¸åšè¿™ä¸ª
- STT é›†æˆ
- PDF æ–‡æœ¬æå–
- è¯­éŸ³åˆæˆ
- RAG æ£€ç´¢
- Prompt æ¨¡æ¿ç®¡ç†ï¼ˆå¯èƒ½ä¾‹å¤–ï¼Œè§ä¸‹æ–‡ï¼‰
```

---

## ğŸ¤” ç°è‰²åœ°å¸¦ï¼šè¾¹ç•Œæ¨¡ç³Šçš„åŠŸèƒ½

### 1. Prompt æ¨¡æ¿ç®¡ç†ï¼Ÿ

**äº‰è®®**ï¼š
- âŒ ä¸åšï¼šPrompt æ˜¯ä¸šåŠ¡ç›¸å…³çš„
- âœ… åšï¼šåŸºç¡€çš„ System Prompt é…ç½®å¾ˆå¸¸è§

**å»ºè®®**ï¼š**å¯ä»¥åšåŸºç¡€ç‰ˆ**
```typescript
// âœ… ç®€å•çš„ System Prompt é…ç½®
<LlmConnectorSettings 
  connectorName="chat"
  defaultSystemPrompt="You are a helpful assistant"
/>

// âŒ ä¸åšå¤æ‚çš„æ¨¡æ¿åº“
<PromptLibrary>
  <PromptTemplate name="translator" />
  <PromptTemplate name="coder" />
</PromptLibrary>
```

### 2. æµå¼å“åº”çš„ UI ç»„ä»¶ï¼Ÿ

**äº‰è®®**ï¼š
- âŒ ä¸åšï¼šè¿™æ˜¯ä¸šåŠ¡ UI
- âœ… åšï¼šæä¾›**æ— æ ·å¼çš„é€»è¾‘ç»„ä»¶**

**å»ºè®®**ï¼š**æä¾› Hookï¼Œä¸æä¾› UI**
```typescript
// âœ… æä¾› Hook
const { 
  isStreaming, 
  currentText, 
  error 
} = useStreamingChat({
  connectorName: 'chat',
  messages,
});

// ç”¨æˆ·è‡ªå·±å®ç° UI
<div>{currentText}</div>
```

### 3. é”™è¯¯é‡è¯•ï¼Ÿ

**å»ºè®®**ï¼š**âœ… åº”è¯¥åš**
```typescript
// å†…ç½®é‡è¯•é€»è¾‘
const result = await llmClient.chat({
  messages,
  retry: {
    maxAttempts: 3,
    backoff: 'exponential',
  },
});
```

---

## ğŸ“¦ æœ€ç»ˆçš„ llm-connector èŒƒå›´

### Package ç»“æ„

```
llm-connector/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ providers/          # âœ… Provider å®ç°
â”‚   â”‚   â”œâ”€â”€ OpenAIProvider.ts
â”‚   â”‚   â”œâ”€â”€ ChromeAIProvider.ts
â”‚   â”‚   â”œâ”€â”€ BackendProxyProvider.ts
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ client/             # âœ… ç»Ÿä¸€å®¢æˆ·ç«¯
â”‚   â”‚   â””â”€â”€ LlmClient.ts
â”‚   â”œâ”€â”€ hooks/              # âœ… React Hooks
â”‚   â”‚   â”œâ”€â”€ useLlmConnector.ts
â”‚   â”‚   â”œâ”€â”€ useLlmConnectorLogic.ts
â”‚   â”‚   â””â”€â”€ useStreamingChat.ts
â”‚   â”œâ”€â”€ components/         # âœ… é…ç½® UI ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ LlmConnectorSettings.tsx
â”‚   â”‚   â”œâ”€â”€ ConnectionStatus.tsx
â”‚   â”‚   â””â”€â”€ TokenUsageDisplay.tsx
â”‚   â”œâ”€â”€ contexts/           # âœ… React Context
â”‚   â”‚   â””â”€â”€ LlmConnectorContext.tsx
â”‚   â”œâ”€â”€ types/              # âœ… TypeScript ç±»å‹
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â””â”€â”€ utils/              # âœ… å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ storage.ts
â”‚       â””â”€â”€ retry.ts
â”œâ”€â”€ docs/                   # âœ… æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ providers.md
â”‚   â”œâ”€â”€ backend-guide.md    # åç«¯å®ç°æŒ‡å—
â”‚   â””â”€â”€ examples/
â”‚       â”œâ”€â”€ nextjs/
â”‚       â”œâ”€â”€ vite/
â”‚       â””â”€â”€ remix/
â””â”€â”€ examples/               # âœ… ç¤ºä¾‹é¡¹ç›®
    â”œâ”€â”€ basic/
    â”œâ”€â”€ with-backend/
    â””â”€â”€ multi-instance/
```

---

## ğŸš€ Google Audio å¦‚ä½•ä½¿ç”¨

### Google Audio çš„èŒè´£

```typescript
// 1. ä½¿ç”¨ llm-connector æä¾›çš„é…ç½®é¢æ¿
<LlmConnectorSettings connectorName="google-audio-chat" />

// 2. ä½¿ç”¨ Hook è·å– LLM å®¢æˆ·ç«¯
const { llmClient } = useLlmConnector('google-audio-chat');

// 3. è‡ªå·±å®ç°ä¸šåŠ¡é€»è¾‘
const ChatInterface = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const { transcript } = useSTT();  // è‡ªå·±çš„ STT Hook
  
  const handleSend = async () => {
    const result = await llmClient.chat({
      messages: [...messages, { role: 'user', content: transcript }],
    });
    
    setMessages([...messages, result]);
  };
  
  return (
    <div className="chat-interface">
      {/* è‡ªå·±çš„ UI */}
      <MessageList messages={messages} />
      <STTControl />
      <InputBox onSend={handleSend} />
    </div>
  );
};
```

---

## ğŸ“Š èŒè´£å¯¹ç…§è¡¨

| åŠŸèƒ½ | llm-connector | Google Audio | è¯´æ˜ |
|------|--------------|--------------|------|
| Provider æŠ½è±¡ | âœ… æ ¸å¿ƒèŒè´£ | âŒ | ç»Ÿä¸€ä¸åŒ LLM æ¥å£ |
| é…ç½®æŒä¹…åŒ– | âœ… æ ¸å¿ƒèŒè´£ | âŒ | localStorage ç®¡ç† |
| é…ç½® UI | âœ… æä¾›å¯é€‰ç»„ä»¶ | âœ… å¯è‡ªå®šä¹‰ | Settings é¢æ¿ |
| å‰åç«¯åˆ‡æ¢ | âœ… æ ¸å¿ƒèŒè´£ | âŒ | callMode ç®¡ç† |
| èŠå¤©ç•Œé¢ | âŒ è¶…å‡ºèŒƒå›´ | âœ… ä¸šåŠ¡èŒè´£ | Message List, Input |
| STT é›†æˆ | âŒ è¶…å‡ºèŒƒå›´ | âœ… ä¸šåŠ¡èŒè´£ | è¯­éŸ³è¯†åˆ« |
| å¯¹è¯å†å² | âŒ è¶…å‡ºèŒƒå›´ | âœ… ä¸šåŠ¡èŒè´£ | çŠ¶æ€ç®¡ç† |
| Prompt å·¥ç¨‹ | âš ï¸ åŸºç¡€æ”¯æŒ | âœ… ä¸šåŠ¡èŒè´£ | System Prompt å¯é… |
| åç«¯ä»£ç†å®ç° | âš ï¸ æä¾›æŒ‡å— | âœ… å®é™…éƒ¨ç½² | æ–‡æ¡£ + ç¤ºä¾‹ |
| é”™è¯¯é‡è¯• | âœ… æ ¸å¿ƒèŒè´£ | âŒ | å†…ç½®é‡è¯•é€»è¾‘ |
| Token ç»Ÿè®¡ | âœ… æ ¸å¿ƒèŒè´£ | âŒ | ä½¿ç”¨é‡è¿½è¸ª |
| è´¹ç”¨ä¼°ç®— | âš ï¸ å¯é€‰åŠŸèƒ½ | âœ… ä¸šåŠ¡å±•ç¤º | æä¾›åŸå§‹æ•°æ® |

---

## ğŸ¯ æœ€ç»ˆå»ºè®®

### å¯¹ llm-connector é¡¹ç›®çš„å»ºè®®

âœ… **åº”è¯¥åš**ï¼š
1. æ·»åŠ  Chrome AIã€LM Studioã€Backend Proxy Providers
2. å®ç°å‰åç«¯æ¨¡å¼åˆ‡æ¢
3. **é›†æˆé…ç½® UI ç»„ä»¶**ï¼ˆSettings Panel, Status, Token Displayï¼‰
4. æä¾›æµå¼å“åº” Hook
5. å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹

âŒ **ä¸åº”è¯¥åš**ï¼š
1. å®Œæ•´çš„èŠå¤©ç•Œé¢
2. å¯¹è¯å†å²ç®¡ç†
3. ä¸šåŠ¡ç›¸å…³çš„ UIï¼ˆSTTã€PDF ç­‰ï¼‰

âš ï¸ **å¯ä»¥è€ƒè™‘**ï¼š
1. åŸºç¡€çš„ System Prompt é…ç½®
2. ç®€å•çš„ Prompt å˜é‡æ›¿æ¢
3. åç«¯å®ç°çš„**è¯¦ç»†æŒ‡å—**å’Œ**ç¤ºä¾‹ä»£ç **

### å¯¹ Google Audio é¡¹ç›®çš„å»ºè®®

âœ… **åº”è¯¥åš**ï¼š
1. ä½¿ç”¨ llm-connector çš„é…ç½®é¢æ¿ï¼ˆæˆ–è‡ªå®šä¹‰ï¼‰
2. å®ç°è‡ªå·±çš„èŠå¤©ç•Œé¢
3. å®ç° STT + AI é›†æˆé€»è¾‘
4. ç®¡ç†å¯¹è¯å†å²

âŒ **ä¸åº”è¯¥åš**ï¼š
1. é‡å¤å®ç° Provider æŠ½è±¡
2. é‡å¤å®ç°é…ç½®æŒä¹…åŒ–

---

## ğŸ“ æ€»ç»“

### llm-connector çš„ä»·å€¼ä¸»å¼ 

> **è®©å¼€å‘è€…ä¸“æ³¨ä¸šåŠ¡ï¼Œè€Œä¸æ˜¯æŠ˜è…¾ LLM é›†æˆ**
> 
> - 5åˆ†é’Ÿæ¥å…¥ä»»ä½• LLM
> - å‰åç«¯æ¨¡å¼éšæ—¶åˆ‡æ¢
> - é…ç½®ç•Œé¢å¼€ç®±å³ç”¨
> - ç±»å‹å®‰å…¨ï¼Œæ–‡æ¡£å®Œå–„

### æˆåŠŸçš„æ ‡å‡†

**çŸ­æœŸ**ï¼ˆv1.0ï¼‰ï¼š
- Google Audio æˆåŠŸé›†æˆ
- PDF Reader æˆåŠŸé›†æˆ
- æ–‡æ¡£å®Œå–„

**é•¿æœŸ**ï¼ˆv2.0+ï¼‰ï¼š
- ä½œä¸ºç‹¬ç«‹ npm åŒ…å‘å¸ƒ
- å…¶ä»–é¡¹ç›®ä¹Ÿèƒ½è½»æ¾ä½¿ç”¨
- ç¤¾åŒºè´¡çŒ® Providers

---

**æ–‡æ¡£å®Œæˆ** âœ…  
**ä¸‹ä¸€æ­¥**ï¼šæ ¹æ®æ­¤å®šä½æ›´æ–°å®æ–½è®¡åˆ’
