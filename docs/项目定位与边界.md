# 项目定位与边界规划

**文档版本**：v1.0  
**创建日期**：2025-10-20  
**角色**：双重规划者视角

---

## ⚠️ 核心架构 - 必读

### 🎯 统一的三种推理模式

**这是一个统一的 LLM 连接器库,支持三种同等重要的推理模式:**

#### 1️⃣ 前端 BYOK (Bring Your Own Key)
- 用户在前端 UI 粘贴自己的 API Key
- Key 存储在浏览器 localStorage
- 前端直接调用 OpenAI/Anthropic/Gemini 等云端 API
- **适用于**: 个人项目、小型应用、用户自己管理密钥

引用 `项目目标.md`:
> 不想自己充值 - 让用户用自己的API Key不香吗?  
> 不想管理用户密钥 - 责任太大,数据安全问题一堆

#### 2️⃣ 端侧推理 (On-Device Inference)
- Chrome AI - 浏览器内置 AI 能力
- WebLLM - 浏览器端 WASM 推理
- 无需 API Key,无需网络,完全本地运行
- **适用于**: 隐私敏感场景、离线使用、免费体验

#### 3️⃣ 后端代理 (Backend Proxy / Local Server)
- Backend Proxy - 企业统一管理 API Key
- LM Studio - 本地模型服务器
- 后端添加密钥,前端无需处理
- **适用于**: 企业内部工具、本地模型、统一管理

**三种模式同等重要,用户根据场景选择合适的模式。**

---

## 🎭 双重视角

### 视角 1：Google Audio 项目负责人
- **目标**：实现 STT + AI 聊天功能
- **需求**：需要一个好用的 LLM 适配层
- **期望**：llm-connector 提供稳定、易用的 API

### 视角 2：llm-connector 库负责人
- **目标**：打造通用的前端 LLM 适配库
- **定位**：类似 `react-query` 之于数据请求
- **边界**：专注适配层，不涉及业务逻辑

---

## 🎯 llm-connector 的定位

### 一句话定位
> **A BYOK React library for unified LLM provider management.**
> 
> 一个基于 BYOK 架构的 React 库，用于统一管理多 LLM 提供商。用户粘贴自己的 API Key，前端直接调用。

### 类比参考
- **类似 `react-query`** - 统一数据请求，但不关心具体业务
- **类似 `react-hook-form`** - 提供表单管理，但不限定表单样式
- **类似 `next-auth`** - 提供认证抽象，但不限定 UI

---

## ✅ llm-connector 应该做什么

### 1. 核心功能：Provider 抽象

```typescript
// 统一接口，屏蔽差异
const result = await llmClient.chat({
  messages: [{ role: 'user', content: 'Hello' }],
  stream: true,
});

// 支持的 Providers
- OpenAI / Anthropic / Gemini  (云端API)
- WebLLM                        (浏览器WASM)
- Chrome AI                     (浏览器内置)
- LM Studio                     (本地服务器)
- Backend Proxy                 (自定义后端)
```

### 2. 状态管理：React Context + Hooks

```typescript
// Provider 组件
<LlmConnectorProvider name="chat" storageKey="chat-config">
  <App />
</LlmConnectorProvider>

// Hook 使用
const { llmClient, states, handlers } = useLlmConnector('chat');

// 多实例支持
<LlmConnectorProvider name="chat">...</LlmConnectorProvider>
<LlmConnectorProvider name="summarizer">...</LlmConnectorProvider>
```

### 3. 配置持久化

```typescript
// 自动保存到 localStorage
{
  "providerId": "openai",
  "apiKey": "sk-...",
  "model": "gpt-4o",
  "callMode": "backend",
  "backendUrl": "/api/ai/proxy"
}
```

### 4. 关键 UI 组件（✅ 推荐集成）

#### 4.1 配置面板 - `<LlmConnectorSettings />`
**功能**：
- Provider 选择下拉框
- API Key 输入（可选）
- Base URL 输入（可选）
- 模型选择
- 前端/后端模式切换
- 连接/断开按钮

**理由**：
- ✅ 这是**配置**而非**业务界面**
- ✅ 每个使用者都需要
- ✅ 可以自定义样式（通过 CSS 或 Tailwind）
- ✅ 可选使用（纯代码配置也可以）

```typescript
// 使用库提供的配置面板
<LlmConnectorSettings 
  connectorName="my-chat"
  showAdvanced={true}
  className="custom-styles"
/>

// 或者完全自定义
const { states, handlers } = useLlmConnector('my-chat');
<MyCustomSettingsUI 
  providerId={states.providerId}
  onProviderChange={handlers.setProviderId}
  // ...
/>
```

#### 4.2 连接状态指示器 - `<ConnectionStatus />`
```typescript
<ConnectionStatus connectorName="my-chat" />
// 显示：🟢 已连接 | 🟡 连接中 | 🔴 未连接
```

#### 4.3 Token 使用统计 - `<TokenUsageDisplay />`
```typescript
<TokenUsageDisplay 
  connectorName="my-chat"
  showCost={true}  // 可选显示费用估算
/>
// 显示：输入 500 tokens | 输出 300 tokens | 约 $0.02
```

### 5. 前后端模式切换

```typescript
// 前端直调（用户提供 API Key）
handlers.setCallMode('frontend');
handlers.setProviderId('openai');
handlers.setApiKey('user-key');

// 后端代理（后端统一管理 API Key）
handlers.setCallMode('backend');
handlers.setBackendUrl('/api/ai/proxy');
```

### 6. 类型安全和文档

```typescript
// 完整的 TypeScript 类型
export interface ChatRequest {
  messages: ChatMessage[];
  model?: string;
  temperature?: number;
  max_tokens?: number;
  stream?: boolean;
}

// 详细的 JSDoc 注释
/**
 * Send a chat message to the LLM
 * @param request - Chat request configuration
 * @returns ChatResult with text, usage, and metadata
 * @throws Error if client is not connected
 */
async chat(request: ChatRequest): Promise<ChatResult>
```

---

## ❌ llm-connector 不应该做什么

### 1. ❌ 完整的聊天界面

```typescript
// ❌ 不提供这个
<ChatInterface>
  <MessageList messages={messages} />
  <InputBox onSend={handleSend} />
  <SidePanel />
</ChatInterface>
```

**理由**：
- 每个项目的聊天界面差异太大
- Google Audio 有 STT 集成、PDF Reader 有分段展示
- 这是**业务 UI**，不是配置 UI

### 2. ❌ 对话历史管理

```typescript
// ❌ 不做这个
const { messages, addMessage, clearHistory } = useChatHistory();
```

**理由**：
- 有人用 Redux，有人用 Zustand，有人用 Context
- 有人存 localStorage，有人存 IndexedDB，有人存后端

### 3. ❌ 后端实现代码

```typescript
// ❌ 不包含这个
// app/api/ai/proxy/route.ts
export async function POST(request: NextRequest) {
  // ...后端代理逻辑
}
```

**理由**：
- 后端技术栈多样（Next.js / Express / Fastify）
- 但可以提供**后端实现指南**和**示例代码**

### 4. ❌ 业务相关功能

```typescript
// ❌ 不做这个
- STT 集成
- PDF 文本提取
- 语音合成
- RAG 检索
- Prompt 模板管理（可能例外，见下文）
```

---

## 🤔 灰色地带：边界模糊的功能

### 1. Prompt 模板管理？

**争议**：
- ❌ 不做：Prompt 是业务相关的
- ✅ 做：基础的 System Prompt 配置很常见

**建议**：**可以做基础版**
```typescript
// ✅ 简单的 System Prompt 配置
<LlmConnectorSettings 
  connectorName="chat"
  defaultSystemPrompt="You are a helpful assistant"
/>

// ❌ 不做复杂的模板库
<PromptLibrary>
  <PromptTemplate name="translator" />
  <PromptTemplate name="coder" />
</PromptLibrary>
```

### 2. 流式响应的 UI 组件？

**争议**：
- ❌ 不做：这是业务 UI
- ✅ 做：提供**无样式的逻辑组件**

**建议**：**提供 Hook，不提供 UI**
```typescript
// ✅ 提供 Hook
const { 
  isStreaming, 
  currentText, 
  error 
} = useStreamingChat({
  connectorName: 'chat',
  messages,
});

// 用户自己实现 UI
<div>{currentText}</div>
```

### 3. 错误重试？

**建议**：**✅ 应该做**
```typescript
// 内置重试逻辑
const result = await llmClient.chat({
  messages,
  retry: {
    maxAttempts: 3,
    backoff: 'exponential',
  },
});
```

---

## 📦 最终的 llm-connector 范围

### Package 结构

```
llm-connector/
├── src/
│   ├── providers/          # ✅ Provider 实现
│   │   ├── OpenAIProvider.ts
│   │   ├── ChromeAIProvider.ts
│   │   ├── BackendProxyProvider.ts
│   │   └── ...
│   ├── client/             # ✅ 统一客户端
│   │   └── LlmClient.ts
│   ├── hooks/              # ✅ React Hooks
│   │   ├── useLlmConnector.ts
│   │   ├── useLlmConnectorLogic.ts
│   │   └── useStreamingChat.ts
│   ├── components/         # ✅ 配置 UI 组件
│   │   ├── LlmConnectorSettings.tsx
│   │   ├── ConnectionStatus.tsx
│   │   └── TokenUsageDisplay.tsx
│   ├── contexts/           # ✅ React Context
│   │   └── LlmConnectorContext.tsx
│   ├── types/              # ✅ TypeScript 类型
│   │   └── index.ts
│   └── utils/              # ✅ 工具函数
│       ├── storage.ts
│       └── retry.ts
├── docs/                   # ✅ 文档
│   ├── README.md
│   ├── providers.md
│   ├── backend-guide.md    # 后端实现指南
│   └── examples/
│       ├── nextjs/
│       ├── vite/
│       └── remix/
└── examples/               # ✅ 示例项目
    ├── basic/
    ├── with-backend/
    └── multi-instance/
```

---

## 🚀 Google Audio 如何使用

### Google Audio 的职责

```typescript
// 1. 使用 llm-connector 提供的配置面板
<LlmConnectorSettings connectorName="google-audio-chat" />

// 2. 使用 Hook 获取 LLM 客户端
const { llmClient } = useLlmConnector('google-audio-chat');

// 3. 自己实现业务逻辑
const ChatInterface = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const { transcript } = useSTT();  // 自己的 STT Hook
  
  const handleSend = async () => {
    const result = await llmClient.chat({
      messages: [...messages, { role: 'user', content: transcript }],
    });
    
    setMessages([...messages, result]);
  };
  
  return (
    <div className="chat-interface">
      {/* 自己的 UI */}
      <MessageList messages={messages} />
      <STTControl />
      <InputBox onSend={handleSend} />
    </div>
  );
};
```

---

## 📊 职责对照表

| 功能 | llm-connector | Google Audio | 说明 |
|------|--------------|--------------|------|
| Provider 抽象 | ✅ 核心职责 | ❌ | 统一不同 LLM 接口 |
| 配置持久化 | ✅ 核心职责 | ❌ | localStorage 管理 |
| 配置 UI | ✅ 提供可选组件 | ✅ 可自定义 | Settings 面板 |
| 前后端切换 | ✅ 核心职责 | ❌ | callMode 管理 |
| 聊天界面 | ❌ 超出范围 | ✅ 业务职责 | Message List, Input |
| STT 集成 | ❌ 超出范围 | ✅ 业务职责 | 语音识别 |
| 对话历史 | ❌ 超出范围 | ✅ 业务职责 | 状态管理 |
| Prompt 工程 | ⚠️ 基础支持 | ✅ 业务职责 | System Prompt 可配 |
| 后端代理实现 | ⚠️ 提供指南 | ✅ 实际部署 | 文档 + 示例 |
| 错误重试 | ✅ 核心职责 | ❌ | 内置重试逻辑 |
| Token 统计 | ✅ 核心职责 | ❌ | 使用量追踪 |
| 费用估算 | ⚠️ 可选功能 | ✅ 业务展示 | 提供原始数据 |

---

## 🎯 最终建议

### 对 llm-connector 项目的建议

✅ **应该做**：
1. 添加 Chrome AI、LM Studio、Backend Proxy Providers
2. 实现前后端模式切换
3. **集成配置 UI 组件**（Settings Panel, Status, Token Display）
4. 提供流式响应 Hook
5. 完善文档和示例

❌ **不应该做**：
1. 完整的聊天界面
2. 对话历史管理
3. 业务相关的 UI（STT、PDF 等）

⚠️ **可以考虑**：
1. 基础的 System Prompt 配置
2. 简单的 Prompt 变量替换
3. 后端实现的**详细指南**和**示例代码**

### 对 Google Audio 项目的建议

✅ **应该做**：
1. 使用 llm-connector 的配置面板（或自定义）
2. 实现自己的聊天界面
3. 实现 STT + AI 集成逻辑
4. 管理对话历史

❌ **不应该做**：
1. 重复实现 Provider 抽象
2. 重复实现配置持久化

---

## 📝 总结

### llm-connector 的价值主张

> **让开发者专注业务，而不是折腾 LLM 集成**
> 
> - 5分钟接入任何 LLM
> - 前后端模式随时切换
> - 配置界面开箱即用
> - 类型安全，文档完善

### 成功的标准

**短期**（v1.0）：
- Google Audio 成功集成
- PDF Reader 成功集成
- 文档完善

**长期**（v2.0+）：
- 作为独立 npm 包发布
- 其他项目也能轻松使用
- 社区贡献 Providers

---

**文档完成** ✅  
**下一步**：根据此定位更新实施计划
