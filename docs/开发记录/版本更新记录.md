## 🎉 v0.4.0 - 聊天功能完整实现版 (2024-12-19)

### ✨ 重大新功能
- 🚀 **useChatManager Hook** - 完整的聊天状态管理解决方案
- 🚀 **ChatInterface 组件** - 现代化聊天UI界面
- 🚀 **流式响应支持** - 实时文本流显示体验
- 🚀 **消息持久化** - 自动保存与恢复聊天历史
- 🚀 **多实例聊天** - 与显式Client名称完美集成

### 🔧 技术特性
- ✅ **声明式配置** - 简洁的Hook配置接口
- ✅ **TypeScript完整支持** - 全类型安全实现
- ✅ **错误处理机制** - 完善的异常捕获与用户提示
- ✅ **请求中断控制** - 支持取消正在进行的生成
- ✅ **响应式设计** - 移动端友好的UI适配
- ✅ **自动消息限制** - 防止内存泄漏的智能清理

### 🎨 用户体验
- ✅ **实时流式显示** - 逐字符显示AI响应过程
- ✅ **加载状态指示** - 清晰的等待和处理提示
- ✅ **键盘快捷键** - Enter发送，Shift+Enter换行
- ✅ **消息气泡设计** - 直观的对话界面布局
- ✅ **错误友好提示** - 网络或API错误的清晰说明

### 📋 集成验证
- ✅ **ChatTest演示页面** - 双实例聊天功能展示
- ✅ **App.tsx集成** - 主应用页面更新展示
- ✅ **多实例隔离验证** - 独立的聊天历史和状态
- ✅ **文档同步更新** - 完整的开发记录和API文档

### 🏗️ 架构创新
- 🎯 **Hook-First设计** - 以Hook为核心的功能架构
- 🎯 **组件化UI** - 高度可复用的聊天组件系统
- 🎯 **配置驱动** - 灵活的功能定制和扩展机制
- 🎯 **集成友好** - 与现有多实例系统无缝结合

### 📊 开发成果
- ✅ 项目功能完整性提升至95%
- ✅ 用户体验层面重大突破
- ✅ 技术架构验证成功
- ✅ 商业化应用基础建立

---

## 🚀 v0.3.5 - 多实例支持完善版 (2024-12-19)

### ✨ 核心突破
- ✅ **显式Client名称传入功能** - 解决React Context"最近上级"不可靠问题
- ✅ **ClientRegistry全局注册系统** - 实现确定性的Client实例管理
- ✅ **双模式并存支持** - Context模式与显式命名模式可同时使用
- ✅ **跨组件树访问能力** - 不再受限于React组件层级结构

### 🔧 技术改进
- ✅ **配置完全隔离** - 每个Client实例拥有独立的状态存储
- ✅ **错误处理增强** - 提供清晰的Client注册和访问错误提示  
- ✅ **开发体验优化** - 简化多实例场景的开发复杂度
- ✅ **测试覆盖完善** - 包含单实例、多实例、边界条件的全面测试

---

## v0.3.2 (12-06-2025)

**Fixed:**
- Fixed an issue with autofocus applying even when embedded chatbot is out of view

## v0.3.1 (11-06-2025)

**Fixed:**
- Fixed an issue with OpenAI Provider not working with `responseFormat` set to `json`

**Added:**
- Added an optional `debug` property to all 3 default providers that prints more verbose logs that may help during development

## v0.3.0 (01-06-2025)

**Fixed:**
- Fixed an issue where the @wllama/wllama package was causing issues for some users

**Note:**

WllamaProvider is no longer shipped by default with the plugin, primarily because packaging it into the plugin causes issues that are hard to resolve plugin-side. There's also a lack of practical use case for it currently, though the default implementation is still available for users to copy into their project [**here**](https://gist.github.com/tjtanjin/345fe484c6df26c8194381d2b177f66c).

## v0.2.0 (16-05-2025)

**Fixed:**
- Fixed an issue where GeminiProvider's `responseFormat` field was required instead of optional
- Fixed an issue where stop conditions do not abort bot streaming responses
- Fixed error message not respecting output type

**Added:**
- Added an `initialMessage` property within the `llmConnector` attribute to allow users to specify an initial message easily

## v0.1.1 (13-05-2025)

**Added:**
- Initial Release