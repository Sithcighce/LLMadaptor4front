# Hooks 开发待办事项

## 📋 当前状态 (2025年9月30日)

### ✅ 已完成 - 基础设施完备！
- [x] 核心基础设施 `useLlmConnectorLogic` - 管理 llmClient 实例
- [x] 连接管理功能 `useConnectionManager` - 服务于基础 UI 组件
- [x] 架构文档 `README.md` - 设计原则和规范
- [x] 基础 UI 组件重构 - ConnectionForm, ModelSelect, TokenUsage
- [x] 修复连接状态逻辑 - 未连接时禁用模型选择等操作
- [x] **🛠️ 工具函数库完整提取** - 从 RCB 中提取的核心工具函数
  - [x] `messageFormatter` - 消息格式转换 ⭐⭐⭐⭐
  - [x] `streamProcessor` - 流式响应处理 ⭐⭐⭐⭐⭐
  - [x] `abortController` - 中断控制 ⭐⭐⭐⭐⭐
  - [x] `errorHandler` - 错误处理和状态恢复 ⭐⭐⭐⭐
  - [x] `keyboardShortcuts` - 快捷键处理 ⭐⭐⭐

### 🎯 当前优势
✅ **完全从 RCB 解离** - 独立的 LLM 连接器库  
✅ **工具函数就绪** - 所有聊天管理核心逻辑已提取  
✅ **架构稳定** - 核心基础设施经过验证  
✅ **设计清晰** - 分层架构，关注点分离

## 🚀 计划开发的功能 Hook

### 1. 🎯 高优先级 - 核心功能

#### `useChatManager` - 聊天功能管理 🚀 **立即可开发**
```typescript
// 目标接口设计 - 基于现有工具函数构建
const {
  // 📝 核心状态
  messages,           // 消息历史
  isStreaming,        // 是否正在流式响应
  error,              // 错误状态
  
  // 🎛️ 核心操作
  sendMessage,        // 发送消息 (集成 streamProcessor)
  clearMessages,      // 清空消息
  retryLastMessage,   // 重试最后一条消息
  abortResponse,      // 中断响应 (基于 abortController)
  
  // 📊 辅助功能
  tokenUsage,         // Token 使用统计
  shortcuts,          // 键盘快捷键 (基于 keyboardShortcuts)
} = useChatManager();
```

**实现策略 - 基于现有工具函数：**
- ✅ **消息管理** → 使用 `messageFormatter` (createUserMessage, createAssistantMessage)
- ✅ **流式响应** → 使用 `streamProcessor` (processStream, StreamProcessor)
- ✅ **中断控制** → 使用 `abortController` (useAbortController)
- ✅ **错误处理** → 使用 `errorHandler` (createErrorHandler)
- ✅ **快捷键** → 使用 `keyboardShortcuts` (useChatKeyboardShortcuts)
- 🔄 **持久化** → 基于 localStorage (参考 useLlmConnectorLogic 模式)
- 🔄 **Token 统计** → 集成到核心基础设施

**对应 UI 组件：**
- `ChatInterface` - 聊天主界面
- `MessageBubble` - 消息气泡
- `InputBox` - 消息输入框
- `StreamingIndicator` - 流式响应指示器

---

#### `useAdvancedSettings` - 高级参数配置
```typescript
// 目标接口设计
const {
  settings,           // 当前参数配置
  updateSetting,      // 更新单个参数
  resetToDefaults,    // 重置为默认值
  importConfig,       // 导入配置
  exportConfig        // 导出配置
} = useAdvancedSettings();
```

**功能需求：**
- [ ] 参数状态管理 (temperature, topK, topP, maxTokens等)
- [ ] 实时参数验证 (范围检查、类型检查)
- [ ] 配置持久化 (localStorage)
- [ ] 参数预设管理 (保存/加载预设配置)
- [ ] 配置导入/导出 (JSON格式)
- [ ] 与 llmClient 的参数同步

**对应 UI 组件：**
- `SettingsPanel` - 主设置面板
- `ParameterSlider` - 参数滑块组件
- `PresetSelector` - 预设配置选择器
- `ConfigImportExport` - 配置导入导出

---

### 2. 🔧 中等优先级 - 扩展功能

#### `useToolRegistry` - 工具注册管理
```typescript
// 目标接口设计
const {
  registeredTools,    // 已注册的工具列表
  availableTools,     // 可用工具列表
  registerTool,       // 注册新工具
  unregisterTool,     // 取消注册工具
  callTool           // 调用工具
} = useToolRegistry();
```

**功能需求：**
- [ ] 工具注册表管理
- [ ] MCP (Model Context Protocol) 支持
- [ ] 工具调用接口
- [ ] 工具权限管理
- [ ] 工具商店集成 (可选)

---

#### `useRAGManager` - RAG 功能管理
```typescript
// 目标接口设计  
const {
  ragConfig,          // RAG 配置
  documents,          // 已索引的文档
  uploadDocument,     // 上传文档
  searchDocuments,    // 搜索文档
  enableRAG,          // 启用 RAG
  disableRAG         // 禁用 RAG
} = useRAGManager();
```

**功能需求：**
- [ ] 向量数据库集成
- [ ] 文档上传和处理
- [ ] 检索配置管理
- [ ] RAG 增强的聊天功能

---

### 3. 🎨 低优先级 - 增强功能

#### `useFineTuningManager` - 微调管理
- [ ] 微调任务创建和监控
- [ ] 数据集管理
- [ ] 模型版本控制

#### `useWorkflowManager` - 工作流管理  
- [ ] 多步骤 LLM 调用链
- [ ] 工作流模板
- [ ] 执行状态管理

#### `useCollaborationManager` - 协作功能
- [ ] 多用户会话共享
- [ ] 消息同步
- [ ] 权限管理

---

## 🎯 使用场景指导

### 场景1：纯"后端"调用 - 逻辑触发
```typescript
// 推荐使用：直接使用核心基础设施
const { llmClient } = useLlmConnectorLogic();

// 简单调用
const result = await llmClient.chat({
  messages: [{ role: 'user', content: '你的问题' }],
  stream: false
});

// 可选：配合工具函数使用
const { createController } = useAbortController();
const controller = createController();
// ...
```

### 场景2：聊天界面调用 - UI 交互
```typescript
// 推荐使用：完整的聊天管理 Hook
const {
  messages, sendMessage, isStreaming,
  clearMessages, abortResponse, error
} = useChatManager(); // 基于工具函数构建

// UI 组件直接使用
<ChatInterface 
  messages={messages}
  onSendMessage={sendMessage}
  isStreaming={isStreaming}
  onAbort={abortResponse}
/>
```

---

## 🎁 项目价值

### 核心优势
1. **🔥 工具函数完备**：从RCB中提取的高质量工具函数，经过实战验证
2. **🏗️ 架构清晰**：分层设计，关注点分离，易于扩展和维护  
3. **⚡ 即用即得**：场景1可立即使用，场景2基于现有工具快速构建
4. **🎯 用户导向**：针对不同使用场景提供最优化的解决方案

### 对不同用户的价值
- **应用开发者**：直接使用Hook构建LLM应用，无需从零开始
- **UI组件开发者**：基于稳定的Hook构建自定义界面组件
- **企业集成商**：将LLM功能快速集成到现有系统中

---

## 🎯 开发优先级

### Phase 1 (当前阶段) - 基础设施 ✅ **已完成**
- [x] 核心架构设计
- [x] 基础连接管理
- [x] UI 组件重构
- [x] 🛠️ **工具函数库完整提取** (关键成果！)

### Phase 2 (立即开始) - 🚀 **useChatManager 开发**
- [ ] **Phase 2.1 - 基础实现**
  - [ ] 消息历史管理 (基于 messageFormatter)
  - [ ] 发送消息功能 (集成 streamProcessor)
  - [ ] 中断控制 (基于 abortController)
  - [ ] 错误处理 (基于 errorHandler)
- [ ] **Phase 2.2 - 增强功能**
  - [ ] 持久化支持 (localStorage)
  - [ ] 快捷键集成 (基于 keyboardShortcuts)
  - [ ] Token 使用统计
- [ ] **Phase 2.3 - UI 组件**
  - [ ] ChatInterface 主界面
  - [ ] MessageBubble 消息气泡
  - [ ] InputBox 输入框

### Phase 3 (后续版本) - 扩展功能
- [ ] `useAdvancedSettings` 实现
- [ ] `useToolRegistry` 实现
- [ ] `useRAGManager` 实现

### Phase 3 (后续版本) - 扩展功能
- [ ] `useToolRegistry` 实现
- [ ] `useRAGManager` 实现
- [ ] 高级 UI 组件开发

### Phase 4 (未来规划) - 生态系统
- [ ] NPM 包发布
- [ ] 文档和示例完善
- [ ] 社区功能和插件系统

---

## 💡 设计决策记录

### 为什么选择当前的架构？
1. **单一数据源** - `llmClient` 作为唯一真实数据源
2. **功能解耦** - 每个 Hook 专注单一功能域
3. **渐进增强** - 可以逐步添加新功能而不影响现有代码
4. **测试友好** - 每个 Hook 都可以独立测试

### 关键设计原则：
- 所有功能 Hook 都依赖核心 `useLlmConnectorLogic`
- UI 组件只使用对应功能域的 Hook
- 保持接口简洁，避免暴露内部实现细节
- 支持渐进式采用，用户可以选择使用部分功能

---

## 📝 注意事项

### 开发时需要考虑的问题：
- [ ] **类型安全** - 确保所有接口都有完整的 TypeScript 类型
- [ ] **错误处理** - 统一的错误处理和用户反馈机制
- [ ] **性能优化** - 避免不必要的重渲染和 API 调用
- [ ] **测试覆盖** - 为每个 Hook 编写单元测试
- [ ] **文档完善** - 每个新功能都要有对应的使用文档和示例

### 兼容性考虑：
- [ ] 确保新功能向后兼容现有接口
- [ ] 支持渐进式迁移路径
- [ ] 考虑不同 LLM Provider 的差异性

---

*创建时间：2025年9月30日*
*负责人：开发团队*
*下次更新：功能开发完成时*